{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping MLB stats from ESPN go###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will try to analyze the batting performances of different teams in Major League Baseball using the data available in the following link http://espn.go.com/mlb/stats/team/_/stat/batting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first scrape the page corresponding to the 2015 season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url=\"http://espn.go.com/mlb/stats/team/_/stat/batting/year/2015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now scrape the table found in the above link. You can follow the class notebook to understand how to capture html table tags.\n",
    "\n",
    "Q1) Write a function which will take the above url and return a pandas dataframe corresponding to the table found in the given link. \n",
    "-Note from Sachin: only keep the information from the teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pandas\n",
    "#pandas.read_csv(\"http://espn.go.com/mlb/stats/team/_/stat/batting/year/2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n<head><script src=\"http://sports-ak.espn.go.com/sports/optimizely.js\"></script><meta charset=\"iso-8859-1\">\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n<link rel=\"icon\" sizes=\"any\" mask href=\"http://a.espncdn.com/prod/assets/icons/E.svg\">\\n<meta name=\"theme-color\" content=\"#CC0000\">\\n<script type=\"text/javascript\">    \\n    if(true && navigator && navigator.userAgent.toLowerCase().indexOf(\"teamstream\") >= 0) {\\n   '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)\n",
    "page.content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tr_elements stands for table row\n",
    "\n",
    "tr_elements = doc.xpath('//tr')\n",
    "[len(T) for T in tr_elements[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 RKTEAMGPABRH2B3BHRTBRBIAVGOBPSLGOPS\n",
      "2 1Toronto16255098911480308172322518852.269.340.457.797\n",
      "3 2NY Yankees16255677641397272192122343737.251.323.421.744\n",
      "4 3Texas16255117511419279321722278707.257.325.413.739\n",
      "5 4Boston16256407481496294331612339706.265.325.415.740\n",
      "6 5Colorado16255727371479274491862409702.265.315.432.748\n",
      "7 6Houston16254597291363278262302383691.250.315.437.752\n",
      "8 7Kansas City16255757241497300421392298689.269.322.412.734\n",
      "9 8Arizona16256497201494289481542341680.264.324.414.738\n",
      "10 9Baltimore16254857131370246202172307686.250.307.421.728\n",
      "11 10Washington16254287031363265131772185665.251.321.403.724\n",
      "12 11Pittsburgh16256316971462292271402228661.260.323.396.719\n",
      "13 12Minnesota16254676961349277441562182661.247.305.399.704\n",
      "14 13San Francisco16255656961486288391362260663.267.326.406.732\n",
      "15 14Oakland16256006941405277461462212661.251.312.395.707\n",
      "16 15Detroit16156056891515289491512355660.270.328.420.748\n",
      "17 16Chicago Cubs16254916891341272301712186657.244.321.398.719\n",
      "18 17NY Mets16255276831351295171772211654.244.312.400.712\n",
      "19 18Cleveland16154396691395303291412179640.256.325.401.725\n",
      "20 19LA Dodgers16253856671346263261872222638.250.326.413.739\n",
      "21 20LA Angels16254176611331243211762144621.246.307.396.702\n",
      "22 21Seattle16255446561379262221982279624.249.311.411.722\n",
      "23 22Milwaukee16254806551378274341452155624.251.307.393.700\n",
      "24 23San Diego16254576501324260361482100623.243.300.385.685\n",
      "25 24St. Louis16254846471386288391372163619.253.321.394.716\n",
      "26 25Tampa Bay16254856441383278321672226612.252.314.406.720\n",
      "27 26Cincinnati16255716401382257271672194613.248.312.394.706\n",
      "28 27Philadelphia16255296261374272371302110586.249.303.382.684\n",
      "29 28Chicago Sox16255336221381260271362103595.250.306.380.686\n",
      "30 29Miami16254636131420236401202096575.260.310.384.694\n",
      "31 30Atlanta16254205731361251181001948548.251.314.359.674\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tr_elements)):\n",
    "    if len(tr_elements[i])==15:\n",
    "        print i, tr_elements[i].text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lxml.html.HtmlElement'>\n",
      "15\n",
      "1:\"14\"\n",
      "2:\"Oakland\"\n",
      "3:\"162\"\n",
      "4:\"5600\"\n",
      "5:\"694\"\n",
      "6:\"1405\"\n",
      "7:\"277\"\n",
      "8:\"46\"\n",
      "9:\"146\"\n",
      "10:\"2212\"\n",
      "11:\"661\"\n",
      "12:\".251\"\n",
      "13:\".312\"\n",
      "14:\".395\"\n",
      "15:\".707\"\n"
     ]
    }
   ],
   "source": [
    "col=[]  # collect column names into col\n",
    "T=tr_elements[15]\n",
    "print type(T)\n",
    "i=0\n",
    "print len(T)\n",
    "for t in T.iterchildren():\n",
    "    i+=1\n",
    "    name=t.text_content()\n",
    "    print '%d:\"%s\"'%(i,name)\n",
    "    col.append((name,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    .251   .312   .395   .707  14  1405  146  162  2212  277  46  5600  661  \\\n",
      "0  0.250  0.315  0.437  0.752   6  1363  230  162  2383  278  26  5459  691   \n",
      "1  0.269  0.322  0.412  0.734   7  1497  139  162  2298  300  42  5575  689   \n",
      "2  0.264  0.324  0.414  0.738   8  1494  154  162  2341  289  48  5649  680   \n",
      "3  0.250  0.307  0.421  0.728   9  1370  217  162  2307  246  20  5485  686   \n",
      "4  0.251  0.321  0.403  0.724  10  1363  177  162  2185  265  13  5428  665   \n",
      "\n",
      "   694      Oakland  \n",
      "0  729      Houston  \n",
      "1  724  Kansas City  \n",
      "2  720      Arizona  \n",
      "3  713    Baltimore  \n",
      "4  703   Washington  \n"
     ]
    }
   ],
   "source": [
    "for j in range(7,len(tr_elements)):\n",
    "    T=tr_elements[j]\n",
    "    if len(T)!=15:\n",
    "        break\n",
    "    i=0\n",
    "    for t in T.iterchildren():\n",
    "        data=t.text_content()\n",
    "        if i!=1:\n",
    "            try:\n",
    "                data=float(data)\n",
    "            except:\n",
    "                print data,'cannot be converted to float, row,col=',j,i\n",
    "                data=None\n",
    "        col[i][1].append(data)\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "[len(C) for (title,C) in col]\n",
    "min_len=min([len(C) for (title,C) in col])\n",
    "Dict={title:column for (title,column) in col}\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(Dict)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SCRAPE_ESPN_MLB_STATS(url):\n",
    "    \n",
    "    raise \"TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above function to scrape season 2015 stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2015 = SCRAPE_ESPN_MLB_STATS(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will now produce plots analyzing performance of different teams on different statistical parameters\n",
    "\n",
    "Q2) Write a function which will take the above dataframe and a list of column names as input and produces a set of plots corresponding to each of the column names provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_plots(df, col_names):\n",
    "    raise \"TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the above function for the columns\n",
    "\n",
    "1. HR: Home Runs\n",
    "2. TB: Total Bases\n",
    "3. RBI: Runs Batted In\n",
    "\n",
    "Q3) We will now use the above functions to scrape for more seasons and analyze the performances over a period of 6 years from 2010-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs={}\n",
    "for year in xrange(0,6):\n",
    "    link = 'http://espn.go.com/mlb/stats/team/_/stat/batting/year/201'+str(year)\n",
    "    dfs[year]=SCRAPE_ESPN_MLB_STATS(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to analyze performance of teams across seasons, we will need all the data in a single dataframe. \n",
    "\n",
    "Q4) Use appropriate pandas functions to combine the above dictionary of year:dataframe to produce one dataframe which has a new column corresponding to the year/season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_df = #combine dfs dictionary with a new column for year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) Now write a function which will take the above dataframe and a list of column names and produces a set of plots corresponding to each of the columns provided. Each plot is a set of subplots, where every subplot is a line graph of the column values over the 6 years for each of the teams in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_plots_over_seasons(combined_df, col_names):\n",
    "    raise \"TODO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the above function for the columns \n",
    "\n",
    "1. HR: Home Runs\n",
    "2. TB: Total Bases\n",
    "3. RBI: Runs Batted In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
