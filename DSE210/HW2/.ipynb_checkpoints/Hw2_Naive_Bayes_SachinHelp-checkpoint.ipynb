{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training Data, Add Labels, Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     labels  label_id\n",
      "0               alt.atheism         1\n",
      "1             comp.graphics         2\n",
      "2   comp.os.ms-windows.misc         3\n",
      "3  comp.sys.ibm.pc.hardware         4\n",
      "4     comp.sys.mac.hardware         5\n",
      "5            comp.windows.x         6\n",
      "6              misc.forsale         7\n",
      "7                 rec.autos         8\n",
      "8           rec.motorcycles         9\n",
      "9        rec.sport.baseball        10\n",
      "   doc_id  word_id  count\n",
      "0       1        1      4\n",
      "1       1        2      2\n",
      "2       1        3     10\n",
      "3       1        4      4\n",
      "4       1        5      2\n",
      "5       1        6      1\n",
      "6       1        7      1\n",
      "7       1        8      1\n",
      "8       1        9      3\n",
      "9       1       10      9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>11240</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>11241</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>11242</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>11243</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11243</th>\n",
       "      <td>11244</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244</th>\n",
       "      <td>11245</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11245</th>\n",
       "      <td>11246</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11246</th>\n",
       "      <td>11247</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>11248</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>11249</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11249</th>\n",
       "      <td>11250</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11250</th>\n",
       "      <td>11251</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11251</th>\n",
       "      <td>11252</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11252</th>\n",
       "      <td>11253</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11253</th>\n",
       "      <td>11254</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11254</th>\n",
       "      <td>11255</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11255</th>\n",
       "      <td>11256</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11256</th>\n",
       "      <td>11257</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11257</th>\n",
       "      <td>11258</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11258</th>\n",
       "      <td>11259</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11259</th>\n",
       "      <td>11260</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>11261</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11261</th>\n",
       "      <td>11262</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11262</th>\n",
       "      <td>11263</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>11264</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>11265</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>11266</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>11267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11267</th>\n",
       "      <td>11268</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  label_id\n",
       "0           1         1\n",
       "1           2         1\n",
       "2           3         1\n",
       "3           4         1\n",
       "4           5         1\n",
       "5           6         1\n",
       "6           7         1\n",
       "7           8         1\n",
       "8           9         1\n",
       "9          10         1\n",
       "10         11         1\n",
       "11         12         1\n",
       "12         13         1\n",
       "13         14         1\n",
       "14         15         1\n",
       "15         16         1\n",
       "16         17         1\n",
       "17         18         1\n",
       "18         19         1\n",
       "19         20         1\n",
       "20         21         1\n",
       "21         22         1\n",
       "22         23         1\n",
       "23         24         1\n",
       "24         25         1\n",
       "25         26         1\n",
       "26         27         1\n",
       "27         28         1\n",
       "28         29         1\n",
       "29         30         1\n",
       "...       ...       ...\n",
       "11239   11240        20\n",
       "11240   11241        20\n",
       "11241   11242        20\n",
       "11242   11243        20\n",
       "11243   11244        20\n",
       "11244   11245        20\n",
       "11245   11246        20\n",
       "11246   11247        20\n",
       "11247   11248        20\n",
       "11248   11249        20\n",
       "11249   11250        20\n",
       "11250   11251        20\n",
       "11251   11252        20\n",
       "11252   11253        20\n",
       "11253   11254        20\n",
       "11254   11255        20\n",
       "11255   11256        20\n",
       "11256   11257        20\n",
       "11257   11258        20\n",
       "11258   11259        20\n",
       "11259   11260        20\n",
       "11260   11261        20\n",
       "11261   11262        20\n",
       "11262   11263        20\n",
       "11263   11264        20\n",
       "11264   11265        20\n",
       "11265   11266        20\n",
       "11266   11267        20\n",
       "11267   11268        20\n",
       "11268   11269        20\n",
       "\n",
       "[11269 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add labels, print dataframes to check\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_map = pd.read_csv('train.map', header = None, delimiter=' ', names= ['labels', 'label_id'])\n",
    "train_data = pd.read_csv('train.data', header = None, delimiter=' ', names=['doc_id', 'word_id', 'count'] )\n",
    "train_label = pd.read_csv('train.label', header = None, delimiter=' ', names= ['label_id'])\n",
    "train_label=train_label.reset_index()\n",
    "train_label.columns = ['doc_id', 'label_id']\n",
    "#add one to the doc ID so that there are no zeroes\n",
    "train_label['doc_id']=train_label['doc_id']+1\n",
    "print train_map[:10]\n",
    "print train_data[:10]\n",
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Training Data Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Total Doc Count & Docs Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get total document count by searching the unique values, this could also be done by taking max of the ID \n",
    "total_doc_count= train_data_joined['doc_id'].unique().shape\n",
    "\n",
    "# Count number of docs for each class\n",
    "docs_per_class=train_data_joined.groupby('label_id').doc_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Pi for Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Pi for Each Class, this is the number of documents in a class/total number of docs\n",
    "df_docs_frac_per_class=np.log(train_data_joined.groupby('label_id').doc_id.nunique()/total_doc_count)\n",
    "pi_values=df_docs_frac_per_class.reset_index()\n",
    "pi_values.columns=['label_id','log_pi']\n",
    "#pi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Total Words Per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_per_class=train_data_joined[['label_id','count']].groupby('label_id').sum().reset_index()\n",
    "words_per_class.columns=['label_id','words_per_label']\n",
    "#words_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Total Words Per Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_id  word_id  count\n",
       "0         1        1     13\n",
       "1         1        2     63\n",
       "2         1        3    275\n",
       "3         1        4      9\n",
       "4         1        5     82"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_words_per_doc=train_data_joined.groupby(['label_id','word_id'])['count'].sum().reset_index()\n",
    "sum_words_per_doc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Training Data Probability Distribution (Pj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SACHIN: THIS IS WHERE I'M HAVING ISSUES, I NEED TO THE PANDAS DATAFRAME UNSTACKED AND THE REST SHOULD WORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11269"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>log(prob)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.019443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.012990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.006152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079470</th>\n",
       "      <td>20</td>\n",
       "      <td>53946</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079471</th>\n",
       "      <td>20</td>\n",
       "      <td>53947</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079472</th>\n",
       "      <td>20</td>\n",
       "      <td>53948</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079473</th>\n",
       "      <td>20</td>\n",
       "      <td>53949</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079474</th>\n",
       "      <td>20</td>\n",
       "      <td>53950</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079475</th>\n",
       "      <td>20</td>\n",
       "      <td>53951</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079476</th>\n",
       "      <td>20</td>\n",
       "      <td>53952</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079477</th>\n",
       "      <td>20</td>\n",
       "      <td>53953</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079478</th>\n",
       "      <td>20</td>\n",
       "      <td>53954</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079479</th>\n",
       "      <td>20</td>\n",
       "      <td>53955</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079480</th>\n",
       "      <td>20</td>\n",
       "      <td>53956</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079481</th>\n",
       "      <td>20</td>\n",
       "      <td>53957</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079482</th>\n",
       "      <td>20</td>\n",
       "      <td>53958</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079483</th>\n",
       "      <td>20</td>\n",
       "      <td>53959</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079484</th>\n",
       "      <td>20</td>\n",
       "      <td>53960</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079485</th>\n",
       "      <td>20</td>\n",
       "      <td>53961</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079486</th>\n",
       "      <td>20</td>\n",
       "      <td>53962</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079487</th>\n",
       "      <td>20</td>\n",
       "      <td>53963</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079488</th>\n",
       "      <td>20</td>\n",
       "      <td>53964</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079489</th>\n",
       "      <td>20</td>\n",
       "      <td>53965</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079490</th>\n",
       "      <td>20</td>\n",
       "      <td>53966</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079491</th>\n",
       "      <td>20</td>\n",
       "      <td>53967</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079492</th>\n",
       "      <td>20</td>\n",
       "      <td>53968</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079493</th>\n",
       "      <td>20</td>\n",
       "      <td>53969</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079494</th>\n",
       "      <td>20</td>\n",
       "      <td>53970</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079495</th>\n",
       "      <td>20</td>\n",
       "      <td>53971</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079496</th>\n",
       "      <td>20</td>\n",
       "      <td>53972</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079497</th>\n",
       "      <td>20</td>\n",
       "      <td>53973</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079498</th>\n",
       "      <td>20</td>\n",
       "      <td>53974</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079499</th>\n",
       "      <td>20</td>\n",
       "      <td>53975</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label_id  word_id  log(prob)\n",
       "0               1        1   0.000067\n",
       "1               1        2   0.000305\n",
       "2               1        3   0.001314\n",
       "3               1        4   0.000048\n",
       "4               1        5   0.000395\n",
       "5               1        6   0.000200\n",
       "6               1        7   0.000033\n",
       "7               1        8   0.000010\n",
       "8               1        9   0.000167\n",
       "9               1       10   0.000671\n",
       "10              1       11   0.000019\n",
       "11              1       12   0.019443\n",
       "12              1       13   0.000081\n",
       "13              1       14   0.000090\n",
       "14              1       15   0.000200\n",
       "15              1       16   0.002662\n",
       "16              1       17   0.001057\n",
       "17              1       18   0.000052\n",
       "18              1       19   0.000038\n",
       "19              1       20   0.000057\n",
       "20              1       21   0.000010\n",
       "21              1       22   0.000010\n",
       "22              1       23   0.012990\n",
       "23              1       24   0.000019\n",
       "24              1       25   0.001452\n",
       "25              1       26   0.000010\n",
       "26              1       27   0.006152\n",
       "27              1       28   0.000081\n",
       "28              1       29   0.034114\n",
       "29              1       30   0.012800\n",
       "...           ...      ...        ...\n",
       "1079470        20    53946   0.000011\n",
       "1079471        20    53947   0.000011\n",
       "1079472        20    53948   0.000017\n",
       "1079473        20    53949   0.000022\n",
       "1079474        20    53950   0.000011\n",
       "1079475        20    53951   0.000011\n",
       "1079476        20    53952   0.000011\n",
       "1079477        20    53953   0.000011\n",
       "1079478        20    53954   0.000011\n",
       "1079479        20    53955   0.000011\n",
       "1079480        20    53956   0.000017\n",
       "1079481        20    53957   0.000017\n",
       "1079482        20    53958   0.000039\n",
       "1079483        20    53959   0.000011\n",
       "1079484        20    53960   0.000011\n",
       "1079485        20    53961   0.000017\n",
       "1079486        20    53962   0.000011\n",
       "1079487        20    53963   0.000017\n",
       "1079488        20    53964   0.000011\n",
       "1079489        20    53965   0.000017\n",
       "1079490        20    53966   0.000011\n",
       "1079491        20    53967   0.000011\n",
       "1079492        20    53968   0.000017\n",
       "1079493        20    53969   0.000011\n",
       "1079494        20    53970   0.000011\n",
       "1079495        20    53971   0.000011\n",
       "1079496        20    53972   0.000011\n",
       "1079497        20    53973   0.000011\n",
       "1079498        20    53974   0.000011\n",
       "1079499        20    53975   0.000011\n",
       "\n",
       "[1079500 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of a specific word in the same class/total number of words in each class\n",
    "#Alpha value for smoothing\n",
    "a = 0.001\n",
    "\n",
    "#Calculate probability of each word based on the class\n",
    "pb_j=train_data_joined.groupby('label_id')\n",
    "pb_ij=train_data_joined[['label_id','word_id','count']].groupby(['label_id','word_id'])\n",
    "prob =  (pb_ij['count'].sum() + 1) / (pb_j['count'].sum() + 61188) \n",
    "k=prob.unstack()\n",
    "k2=k.fillna(1.0/61188)\n",
    "k3=k2.stack()\n",
    "prob_distr=k3.reset_index()\n",
    "prob_distr.columns=['label_id','word_id','log(prob)']\n",
    "prob_distr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.unstack of          label_id  word_id         0\n",
       "0               1        1  0.000067\n",
       "1               1        2  0.000305\n",
       "2               1        3  0.001314\n",
       "3               1        4  0.000048\n",
       "4               1        5  0.000395\n",
       "5               1        6  0.000200\n",
       "6               1        7  0.000033\n",
       "7               1        8  0.000010\n",
       "8               1        9  0.000167\n",
       "9               1       10  0.000671\n",
       "10              1       11  0.000019\n",
       "11              1       12  0.019443\n",
       "12              1       13  0.000081\n",
       "13              1       14  0.000090\n",
       "14              1       15  0.000200\n",
       "15              1       16  0.002662\n",
       "16              1       17  0.001057\n",
       "17              1       18  0.000052\n",
       "18              1       19  0.000038\n",
       "19              1       20  0.000057\n",
       "20              1       21  0.000010\n",
       "21              1       22  0.000010\n",
       "22              1       23  0.012990\n",
       "23              1       24  0.000019\n",
       "24              1       25  0.001452\n",
       "25              1       26  0.000010\n",
       "26              1       27  0.006152\n",
       "27              1       28  0.000081\n",
       "28              1       29  0.034114\n",
       "29              1       30  0.012800\n",
       "...           ...      ...       ...\n",
       "1079470        20    53946  0.000011\n",
       "1079471        20    53947  0.000011\n",
       "1079472        20    53948  0.000017\n",
       "1079473        20    53949  0.000022\n",
       "1079474        20    53950  0.000011\n",
       "1079475        20    53951  0.000011\n",
       "1079476        20    53952  0.000011\n",
       "1079477        20    53953  0.000011\n",
       "1079478        20    53954  0.000011\n",
       "1079479        20    53955  0.000011\n",
       "1079480        20    53956  0.000017\n",
       "1079481        20    53957  0.000017\n",
       "1079482        20    53958  0.000039\n",
       "1079483        20    53959  0.000011\n",
       "1079484        20    53960  0.000011\n",
       "1079485        20    53961  0.000017\n",
       "1079486        20    53962  0.000011\n",
       "1079487        20    53963  0.000017\n",
       "1079488        20    53964  0.000011\n",
       "1079489        20    53965  0.000017\n",
       "1079490        20    53966  0.000011\n",
       "1079491        20    53967  0.000011\n",
       "1079492        20    53968  0.000017\n",
       "1079493        20    53969  0.000011\n",
       "1079494        20    53970  0.000011\n",
       "1079495        20    53971  0.000011\n",
       "1079496        20    53972  0.000011\n",
       "1079497        20    53973  0.000011\n",
       "1079498        20    53974  0.000011\n",
       "1079499        20    53975  0.000011\n",
       "\n",
       "[1079500 rows x 3 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #add one for all of the null values as (1/count+V+1)\n",
    "# for c in range(1,21):\n",
    "#     prob_distr.loc[c,:] = prob_distr.loc[c,:].fillna(a/(pb_j['count'].sum()[c] + 16689))\n",
    "    \n",
    "# #Convert to dictionary for greater speed\n",
    "# prob_distr_dict = prob_distr.to_dict()\n",
    "\n",
    "# #prob_distr=prob_distr.reset_index()\n",
    "# x=prob_distr.unstack\n",
    "# x\n",
    "# ###### I NEED X AS IT IS HERE Reindexed, But I cant save the instance Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                test_labels  test_label_id\n",
      "0               alt.atheism              1\n",
      "1             comp.graphics              2\n",
      "2   comp.os.ms-windows.misc              3\n",
      "3  comp.sys.ibm.pc.hardware              4\n",
      "4     comp.sys.mac.hardware              5\n",
      "   test_doc_id  test_word_id  test_count\n",
      "0            1             3           1\n",
      "1            1            10           1\n",
      "2            1            12           8\n",
      "3            1            17           1\n",
      "4            1            23           8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_doc_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_doc_id  label_id\n",
       "0            0         1\n",
       "1            1         1\n",
       "2            2         1\n",
       "3            3         1\n",
       "4            4         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_map = pd.read_csv('test.map', header = None, delimiter=' ', names= ['test_labels', 'test_label_id'])\n",
    "test_data = pd.read_csv('test.data', header = None, delimiter=' ', names=['test_doc_id', 'test_word_id', 'test_count'] )\n",
    "test_label = pd.read_csv('test.label', header = None, delimiter=' ', names= ['test_label_id'])\n",
    "test_label=test_label.reset_index()\n",
    "test_label.columns = ['test_doc_id', 'label_id']\n",
    "print test_map.head(5)\n",
    "print test_data.head(5)\n",
    "test_label.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_doc_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>test_word_id</th>\n",
       "      <th>test_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_doc_id  label_id  test_word_id  test_count\n",
       "0            1         1             3           1\n",
       "1            1         1            10           1\n",
       "2            1         1            12           8\n",
       "3            1         1            17           1\n",
       "4            1         1            23           8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_label['test_doc_id']=test_label['test_doc_id']\n",
    "merged_test_data = pd.merge( test_label, test_data, on='test_doc_id', how=\"inner\")\n",
    "merged_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Single Test Document for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_doc_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>test_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_doc_id  label_id  word_id  test_count\n",
       "0            1         1        3           1\n",
       "1            1         1       10           1\n",
       "2            1         1       12           8\n",
       "3            1         1       17           1\n",
       "4            1         1       23           8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=merged_test_data.loc[merged_test_data['test_doc_id']==1];\n",
    "df.columns = df.columns.str.replace('test_word_id','word_id')\n",
    "#sum_words_per_doc=df.groupby(['word_id','doc_id'])['count'].sum().reset_index()\n",
    "sum_words_per_doc.head(5)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Bayesian Algorithm: Map Probability for a Doc that Belongs to Each Class\n",
    "#1) Match on Doc ID, #2 Pull Out Label ID, Probability Word Belongs to that class, and count of word occurence in document; sort by word ID so you can see the map of each word mapping to each class #3 multiply words to get prior probability #4 sum prior probability over each class (it can be added due to the log). #5 raname so that ID's line up and pie values for each class can be multiplied #6 add up the pi with the prior prob, can add because of the log values #7 Answer gives the probability that the document belongs to each class\n",
    "#Log(Probability(word/class)^N,words)summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['log(prob)'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9c4203fc4cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_distr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_id_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'word_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'log(prob)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label_id_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msingle_doc_dist\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'prior_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log(prob)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_id_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msingle_doc_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prior_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ryanriopelle/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1964\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ryanriopelle/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ryanriopelle/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['log(prob)'] not in index\""
     ]
    }
   ],
   "source": [
    "single_doc_dist= pd.merge(prob_distr,df, on='word_id')\n",
    "single_doc_dist= single_doc_dist[['label_id_x','word_id','log(prob)','test_count']].sort_values(['word_id','label_id_x'])\n",
    "single_doc_dist ['prior_prob']= single_doc_dist['test_count']*single_doc_dist['log(prob)']\n",
    "single_doc_dist=single_doc_dist.groupby(['label_id_x'])['prior_prob'].sum().round(3).reset_index()\n",
    "single_doc_dist.columns=['label_id','prior_prob']\n",
    "single_doc_dist = pd.merge (single_doc_dist,pi_values, on='label_id' )\n",
    "single_doc_dist['probability']=single_doc_dist['prior_prob']+single_doc_dist['log_pi']\n",
    "single_doc_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_doc_dist['probability'].idxmax()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Function to Classify One Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SingleDoc_NaiveBayesClassifier(doc):\n",
    "    df=merged_test_data.loc[merged_test_data['test_doc_id']==doc];\n",
    "    df.columns = df.columns.str.replace('test_word_id','word_id')\n",
    "    ###### Copy below this line, above is for the function\n",
    "    single_doc_dist= pd.merge(prob_distr,df, on='word_id')\n",
    "    single_doc_dist= single_doc_dist[['label_id_x','word_id','log(prob)','test_count']].sort_values(['word_id','label_id_x'])\n",
    "    single_doc_dist ['prior_prob']= single_doc_dist['test_count']*single_doc_dist['log(prob)']\n",
    "    single_doc_dist=single_doc_dist.groupby(['label_id_x'])['prior_prob'].sum().round(3).reset_index()\n",
    "    single_doc_dist.columns=['label_id','prior_prob']\n",
    "    single_doc_dist = pd.merge (single_doc_dist,pi_values, on='label_id' )\n",
    "    single_doc_dist['probability']=single_doc_dist['prior_prob']+single_doc_dist['log_pi']\n",
    "    class_rating = single_doc_dist['probability'].idxmax()+1\n",
    "    print class_rating\n",
    "SingleDoc_NaiveBayesClassifier(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup New Classifier Function for All Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sachin, I would like to finish this tomorrow, I cant find the error that is \n",
    "# giving 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_doc_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>7475</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>7476</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>7477</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>7478</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>7479</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>7480</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>7481</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>7482</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>7483</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>7484</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>7485</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>7486</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>7487</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>7488</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>7489</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>7490</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>7491</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>7492</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>7493</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>7494</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>7495</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>7496</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>7497</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>7498</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>7499</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>7500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>7501</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7501</th>\n",
       "      <td>7502</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>7503</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>7504</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7504 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_doc_id  label_id\n",
       "0               1         1\n",
       "1               2         1\n",
       "2               3         1\n",
       "3               4         1\n",
       "4               5         1\n",
       "5               6         1\n",
       "6               7         1\n",
       "7               8         1\n",
       "8               9         1\n",
       "9              10         1\n",
       "10             11         1\n",
       "11             12         1\n",
       "12             13         1\n",
       "13             14         1\n",
       "14             15         1\n",
       "15             16         1\n",
       "16             17         1\n",
       "17             18         1\n",
       "18             19         1\n",
       "19             20         1\n",
       "20             21         1\n",
       "21             22         1\n",
       "22             23         1\n",
       "23             24         1\n",
       "24             25         1\n",
       "25             26         1\n",
       "26             27         1\n",
       "27             28         1\n",
       "28             29         1\n",
       "29             30         1\n",
       "...           ...       ...\n",
       "7474         7475        20\n",
       "7475         7476        20\n",
       "7476         7477        20\n",
       "7477         7478        20\n",
       "7478         7479        20\n",
       "7479         7480        20\n",
       "7480         7481        20\n",
       "7481         7482        20\n",
       "7482         7483        20\n",
       "7483         7484        20\n",
       "7484         7485        20\n",
       "7485         7486        20\n",
       "7486         7487        20\n",
       "7487         7488        20\n",
       "7488         7489        20\n",
       "7489         7490        20\n",
       "7490         7491        20\n",
       "7491         7492        20\n",
       "7492         7493        20\n",
       "7493         7494        20\n",
       "7494         7495        20\n",
       "7495         7496        20\n",
       "7496         7497        20\n",
       "7497         7498        20\n",
       "7498         7499        20\n",
       "7499         7500        20\n",
       "7500         7501        20\n",
       "7501         7502        20\n",
       "7502         7503        20\n",
       "7503         7504        20\n",
       "\n",
       "[7504 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NaiveBayesClassifier(df):\n",
    "    df_all= df\n",
    "    df_all.columns = df_all.columns.str.replace('test_word_id','word_id')\n",
    "    all_doc_dist= pd.merge(prob_distr,df_all, on=['label_id','word_id'])\n",
    "    all_doc_dist= all_doc_dist[['label_id','word_id','log(prob)','test_count','test_doc_id']].sort_values(['word_id','label_id'])\n",
    "    all_doc_dist ['prior_prob']= all_doc_dist['test_count']*all_doc_dist['log(prob)']\n",
    "    all_doc_dist=all_doc_dist.groupby(['test_doc_id','label_id'])['prior_prob'].sum().reset_index()\n",
    "    all_doc_dist.columns=['test_doc_id','label_id','prior_prob']\n",
    "    all_doc_dist = pd.merge (all_doc_dist,pi_values, on='label_id' )\n",
    "    all_doc_dist['probability']=all_doc_dist['prior_prob']+all_doc_dist['log_pi']\n",
    "    classified_dataframe= all_doc_dist.sort_values('probability', ascending=False).groupby('test_doc_id', as_index=False).first()\n",
    "    classified_dataframe= classified_dataframe[['test_doc_id','label_id']]\n",
    "    return classified_dataframe\n",
    "classified_dataframe=NaiveBayesClassifier(merged_test_data)\n",
    "# print classified_dataframe\n",
    "classified_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy of Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_label.columns = ['doc_id', 'test_label_id']\n",
    "classified_dataframe.columns = ['doc_id', 'predicted_label_id']\n",
    "guess_to_real= pd.merge(classified_dataframe,test_label, on='doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess_to_real['err']=guess_to_real.apply(lambda row:row['predicted_label_id']-row['test_label_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(guess_to_real['err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>modified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>december</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atheist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>addresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>organizations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>freedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>darwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bumper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stickers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>assorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>paraphernalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61158</th>\n",
       "      <td>sectarians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61159</th>\n",
       "      <td>talmage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61160</th>\n",
       "      <td>preexistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61161</th>\n",
       "      <td>exod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61162</th>\n",
       "      <td>tetragrammation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61163</th>\n",
       "      <td>triune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>adon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>atoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61166</th>\n",
       "      <td>tidings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>maketh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61168</th>\n",
       "      <td>spreadeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61169</th>\n",
       "      <td>bhagwans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>anchovy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61171</th>\n",
       "      <td>vanishingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61172</th>\n",
       "      <td>ktikkane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61173</th>\n",
       "      <td>ramses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61174</th>\n",
       "      <td>orontes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61175</th>\n",
       "      <td>chariotry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>amun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>deist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>devoutly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61179</th>\n",
       "      <td>smugly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61180</th>\n",
       "      <td>tartaros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61181</th>\n",
       "      <td>bibical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61182</th>\n",
       "      <td>tophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61183</th>\n",
       "      <td>aeroplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>gosple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>ephas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>kltensme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>etrbom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vocab\n",
       "0              archive\n",
       "1                 name\n",
       "2              atheism\n",
       "3            resources\n",
       "4                  alt\n",
       "5                 last\n",
       "6             modified\n",
       "7             december\n",
       "8              version\n",
       "9              atheist\n",
       "10           addresses\n",
       "11                  of\n",
       "12       organizations\n",
       "13                 usa\n",
       "14             freedom\n",
       "15                from\n",
       "16            religion\n",
       "17          foundation\n",
       "18              darwin\n",
       "19                fish\n",
       "20              bumper\n",
       "21            stickers\n",
       "22                 and\n",
       "23            assorted\n",
       "24               other\n",
       "25       paraphernalia\n",
       "26                 are\n",
       "27           available\n",
       "28                 the\n",
       "29                  in\n",
       "...                ...\n",
       "61158       sectarians\n",
       "61159          talmage\n",
       "61160      preexistent\n",
       "61161             exod\n",
       "61162  tetragrammation\n",
       "61163           triune\n",
       "61164             adon\n",
       "61165          atoning\n",
       "61166          tidings\n",
       "61167           maketh\n",
       "61168        spreadeth\n",
       "61169         bhagwans\n",
       "61170          anchovy\n",
       "61171      vanishingly\n",
       "61172         ktikkane\n",
       "61173           ramses\n",
       "61174          orontes\n",
       "61175        chariotry\n",
       "61176             amun\n",
       "61177            deist\n",
       "61178         devoutly\n",
       "61179           smugly\n",
       "61180         tartaros\n",
       "61181          bibical\n",
       "61182           tophet\n",
       "61183        aeroplane\n",
       "61184           gosple\n",
       "61185            ephas\n",
       "61186         kltensme\n",
       "61187           etrbom\n",
       "\n",
       "[61188 rows x 1 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('vocabulary.txt', header = None, delimiter=' ', names= ['vocab'])\n",
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vocab=61188\n",
    "#Vocab*20=1223760\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
